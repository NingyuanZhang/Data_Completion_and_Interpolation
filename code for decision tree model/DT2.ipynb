{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet) #数据集大小\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]   #获取分类标签\n",
    "        if currentLabel not in labelCounts.keys(): labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1  #每个类中数据个数统计\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:  #信息熵计算\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob,2) \n",
    "    return shannonEnt\n",
    "    \n",
    "def splitDataSet(data,feature,value):\n",
    "    #return splitted data\n",
    "    newdata=[]\n",
    "    for rows in data:\n",
    "        if rows[feature]==value : \n",
    "            reduceFeatVec=rows[:feature]\n",
    "            reduceFeatVec.extend(rows[feature+1:])\n",
    "            newdata.append(reduceFeatVec)\n",
    "    return newdata \n",
    "    \n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1  #计算分类依据的个数\n",
    "    baseEntropy = calcShannonEnt(dataSet)   #计算原始分类的信息熵\n",
    "    bestInfoGain = 0.0; \n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):    #对apple进行分类\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:  #计算该种分类的信息熵\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)     \n",
    "        infoGain = baseEntropy - newEntropy  #计算当前分类的信息增益\n",
    "        if (infoGain > bestInfoGain):  #比较那种分类的信息增益最大并返回\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i    \n",
    "    return bestFeature\n",
    "def majority(labelValues):\n",
    "    labelCount =dict()\n",
    "    for label in labelValues:\n",
    "        labelCount[label]=labelCount.setdefault(label,0)+1\n",
    "    labelCountSort = sorted(labelCount.items(),key = lambda x:x[1],reverse=True)\n",
    "    return labelCountSort[0][0]\n",
    "\n",
    "    \n",
    "def createTree(dataSet,features):\n",
    "    labelValues = [data[-1] for data in dataSet]\n",
    "    if labelValues.count(labelValues[0])==len(labelValues): #全部为同一类别\n",
    "        return labelValues[0]\n",
    "    if len(dataSet[0])==1: #特征为空\n",
    "        return majority(labelValues)\n",
    "    bestAxis = chooseBestFeatureToSplit(dataSet)#最优特征下标,信息增益     \n",
    "    bestFeature = features[bestAxis]#最优特征值\n",
    "    ID3Tree ={bestFeature:{}}#构造决策树\n",
    "        \n",
    "    del(features[bestAxis]) #对每一个子集，以｛全部特征-特征Ａ｝为特征\n",
    "\n",
    "    featureValues = set([data[bestAxis] for data in dataSet])\n",
    "    for key in featureValues:\n",
    "        subFeatures = features[:]\n",
    "        subDataSet = splitDataSet(dataSet,bestAxis,key)\n",
    "        ID3Tree[bestFeature][key] = createTree(subDataSet,subFeatures)\n",
    "    return ID3Tree\n",
    "def preres(row,mytree,labels):\n",
    "    res=-1\n",
    "    firstStr=list(mytree.keys())[0]\n",
    "    index=labels.index(firstStr)\n",
    "    secondDict=mytree[firstStr]\n",
    "    num_of_choice=len(list(secondDict.keys()))\n",
    "\n",
    "    for i in range(num_of_choice):\n",
    "        value=list(secondDict.keys())[i]\n",
    "        if row[index]==value:\n",
    "            if type(secondDict[value]).__name__=='dict':\n",
    "                return preres(row,secondDict[value],labels)\n",
    "            else:\n",
    "                res=secondDict[value]\n",
    "                return res\n",
    "        else: continue\n",
    "    \n",
    "def calerrtr(data,mytree,labels): \n",
    "    err_train=0\n",
    "    for i in range(len(data)):\n",
    "        row=data[i]\n",
    "        pre=preres(row,mytree,labels)\n",
    "        if (pre==row[-1]):\n",
    "            pass\n",
    "        else:\n",
    "            err_train+=1\n",
    "    print(err_train/len(data))\n",
    "    return err_train/len(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "def createDataSet():\n",
    "   \n",
    "    label=[]\n",
    "    for i in range(13):\n",
    "        label.append(\"feature\"+str(i+1))\n",
    "    \n",
    "    df=pd.read_csv(r'mcmost1_train.csv')\n",
    "    #print(df)\n",
    "    data_1=np.array(df)\n",
    "    data_2=data_1.tolist()\n",
    "    data_all=[i[1:] for i in data_2]\n",
    "    total_num=len(data_all)\n",
    "    data_train=data_all[0:math.floor(0.8*total_num)]\n",
    "    data_test=data_all[math.floor(0.8*total_num):]\n",
    "    return data_train,data_test,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train,data_test,labels=createDataSet()\n",
    "data=data_train\n",
    "labelstmp=[]\n",
    "for i in range (len(labels)):\n",
    "    labelstmp.append(labels[i])\n",
    "mytree=createTree(data,labelstmp)\n",
    "#print(mytree)\n",
    "calerrtr(data_train,mytree,labels)\n",
    "calerrtr(data_test,mytree,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTreepru1(dataSet,features,depth,d=1):\n",
    "    labelValues = [data[-1] for data in dataSet]\n",
    "    if labelValues.count(labelValues[0])==len(labelValues): #全部为同一类别\n",
    "        return labelValues[0]\n",
    "    if len(dataSet[0])==1 or d>=depth: #特征为空\n",
    "        return majority(labelValues)\n",
    "        \n",
    "    bestAxis = chooseBestFeatureToSplit(dataSet)#最优特征下标,信息增益     \n",
    "    bestFeature = features[bestAxis]#最优特征值\n",
    "    ID3Tree ={bestFeature:{}}#构造决策树\n",
    "        \n",
    "    del(features[bestAxis]) #对每一个子集，以｛全部特征-特征Ａ｝为特征\n",
    "\n",
    "    featureValues = set([data[bestAxis] for data in dataSet])\n",
    "    for key in featureValues:\n",
    "        subFeatures = features[:]\n",
    "        subDataSet = splitDataSet(dataSet,bestAxis,key)\n",
    "        ID3Tree[bestFeature][key] = createTreepru1(subDataSet,subFeatures,depth,d+1)\n",
    "    return ID3Tree\n",
    "\n",
    "\n",
    "def createTreepru2(dataSet,features,samplesize):\n",
    "    labelValues = [data[-1] for data in dataSet]\n",
    "    if labelValues.count(labelValues[0])==len(labelValues): #全部为同一类别\n",
    "        return labelValues[0]\n",
    "    if len(dataSet[0])==1 or len(dataSet)<=samplesize: #特征为空\n",
    "        return majority(labelValues)\n",
    "        \n",
    "    bestAxis = chooseBestFeatureToSplit(dataSet)#最优特征下标,信息增益     \n",
    "    bestFeature = features[bestAxis]#最优特征值\n",
    "    ID3Tree ={bestFeature:{}}#构造决策树\n",
    "        \n",
    "    del(features[bestAxis]) #对每一个子集，以｛全部特征-特征Ａ｝为特征\n",
    "\n",
    "    featureValues = set([data[bestAxis] for data in dataSet])\n",
    "    for key in featureValues:\n",
    "        subFeatures = features[:]\n",
    "        subDataSet = splitDataSet(dataSet,bestAxis,key)\n",
    "        ID3Tree[bestFeature][key] = createTreepru2(subDataSet,subFeatures,samplesize)\n",
    "    return ID3Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature13': {1.0: 2.0, 2.0: 2.0, 3.0: 2.0, 4.0: 2.0, 5.0: 2.0, 6.0: 2.0, 7.0: 2.0}}\n"
     ]
    }
   ],
   "source": [
    "data_train,data_test,labels=createDataSet()\n",
    "data=data_train\n",
    "labelstmp=[]\n",
    "for i in range (len(labels)):\n",
    "    labelstmp.append(labels[i])\n",
    "mytree=createTreepru1(data,labelstmp,2)\n",
    "print(mytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18055555555555555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18055555555555555"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calerrtr(data_test,mytree,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def loadDataset(infile):\n",
    "    df = pd.read_csv(infile, sep='\\t', header=None, dtype=str, na_filter=False)\n",
    "    #df_file=pd.DataFrame(np.array(df).astype(np.float),columns=features)\n",
    "    #return df_file\n",
    "    return np.array(df).astype(np.float)\n",
    "\n",
    "a=loadDataset(\"ticdata2000.txt\")\n",
    "a=a.tolist()\n",
    "data=a\n",
    "\n",
    "label=[]\n",
    "for i in range(86):\n",
    "    label.append(\"feature\"+str(i+1))\n",
    "    \n",
    "labelstmp=[]\n",
    "for i in range (len(label)):\n",
    "    labelstmp.append(label[i])\n",
    "res=rankFeatureToSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1  #计算分类依据的个数\n",
    "    baseEntropy = calcShannonEnt(dataSet)   #计算原始分类的信息熵\n",
    "    bestInfoGain = 0.0; \n",
    "    rankFeature = dict()\n",
    "    for i in range(numFeatures):    #对apple进行分类\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:  #计算该种分类的信息熵\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)     \n",
    "        infoGain = baseEntropy - newEntropy  #计算当前分类的信息增益\n",
    "        rankFeature[i]=rankFeature.setdefault(i,0)+infoGain\n",
    "    return rankFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.015260720872135203, 1: 0.0007972822836823656, 2: 0.001287692808422225, 3: 0.0005673619228074855, 4: 0.010969412972420545, 5: 0.001325673540907235, 6: 0.002717666510158423, 7: 0.0014978297648832184, 8: 0.0026618466803074448, 9: 0.004403065917262972, 10: 0.0013805581447980941, 11: 0.004094660202578981, 12: 0.0025870964022050025, 13: 0.0007919611356045908, 14: 0.0015812407664169692, 15: 0.0051803347071330275, 16: 0.0022013867339356064, 17: 0.006831164233656373, 18: 0.004038144610563732, 19: 0.0005314337561095894, 20: 0.003038820977239731, 21: 0.002817611106230633, 22: 0.0038777631096795218, 23: 0.003055046551533658, 24: 0.0057033267101205265, 25: 0.002258365457761924, 26: 0.0006301586559178673, 27: 0.003965423638379428, 28: 0.003843912099470992, 29: 0.0058723926584536845, 30: 0.00580995979980925, 31: 0.005004381154667004, 32: 0.0001843989563080073, 33: 0.0061478583256497354, 34: 0.0032251182946089196, 35: 0.0030691580471602364, 36: 0.007133877723624893, 37: 0.0007340288912277559, 38: 0.004851469551506782, 39: 0.003294356935594156, 40: 0.0006790463509995237, 41: 0.009392211154289565, 42: 0.00875629669206579, 43: 0.006747971947769604, 44: 0.0006388420483109392, 45: 0.0004806322640720784, 46: 0.024113270638014717, 47: 0.00019937857002000348, 48: 0.0014376535954119807, 49: 0.00013756670189146725, 50: 0.0004541045367901231, 51: 0.0007284545643484464, 52: 0.000321331121116597, 53: 0.002368869330813206, 54: 0.0014045086203084423, 55: 0.00019954781589576198, 56: 0.000967303203738612, 57: 0.0006621294230047536, 58: 0.017016313518174786, 59: 0.0003853797907858447, 60: 0.004464414391319671, 61: 0.0004984648715379292, 62: 0.0005999660354398806, 63: 0.0023154399264244674, 64: 0.005880051124325492, 65: 1.5952474717306764e-05, 66: 0.00041160626065334105, 67: 0.01701511136600309, 68: 0.0001313643772351547, 69: 0.00010457249204204322, 70: 0.00013756670189146725, 71: 0.0002844362116243282, 72: 0.0003141665178542641, 73: 0.000321331121116597, 74: 0.0019836140438384553, 75: 0.001503210117008713, 76: 6.186557112908275e-05, 77: 0.0005755822438246461, 78: 0.0006621294230047536, 79: 0.004345507621150879, 80: 0.0002557185915135207, 81: 0.003956964182444012, 82: 0.0007801400362903999, 83: 0.00024317635335247, 84: 0.0022505490804075046}\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "sorted(res.items(), key=itemgetter(1), reverse=True)[0:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ffff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hhkjk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
